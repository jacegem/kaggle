{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this chanllenge, Santander invites Kagglers to help them identify which customers will make a specific transaction in the future, irrespective of the amount of money transcated. The data provided for this competiton has the same structure as the real data they have available to solve this problem.\n",
    "\n",
    "The data is anonimyzed, each row containing 200 numerical values identified just with a number.\n",
    "\n",
    "In the following we will explore the data, prepare it for a model, train a model and predict the target value for the test set, then prepare a submission.\n",
    "\n",
    "Stay tuned, I will frequently update this Kernel in the next days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOCAL = True\n",
    "if(IS_LOCAL):\n",
    "    PATH=\"./\"\n",
    "else:\n",
    "    PATH=\"../input/\"\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "train_df = pd.read_csv(PATH+\"train.csv\")\n",
    "test_df = pd.read_csv(PATH+\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "## Check the data\n",
    "\n",
    "Let's check the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both train and test data have 200,000 entries and 202, respectivelly 201 columns.\n",
    "Let's glimpse train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train contains:\n",
    "\n",
    "- ID_code (string)\n",
    "- target;\n",
    "- 200 numerical variables, named from var_0 to var_199\n",
    "\n",
    "Test contains:\n",
    "\n",
    "- ID_code (string)\n",
    "- 200 numerical vairables, named to var_0 to var_199\n",
    "\n",
    "Let's check if there are any missing data. We will also check the type of data.\n",
    "\n",
    "We check first train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(data):\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in data.columns:\n",
    "        dtype = str(data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    tt['Types'] = types\n",
    "    return(np.transpose(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "missing_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "missing_data(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing data in train and test datasets. Let's check the numerical values in train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make few observations here:\n",
    "\n",
    "- standard deviation is relatively large for both train and test vaiable data\n",
    "- min, max, mean, std values for trian and test data looks quite close\n",
    "- mean values are distributed over a large range\n",
    "\n",
    "The number of values in train and test set is the same. Let's plot the scatter plot for train and teset set for few of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_scatter(df1, df2, features):\n",
    "    i = 0\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(4,4,figsize=(14,14))\n",
    "\n",
    "    for feature in features:\n",
    "        i += 1\n",
    "        plt.subplot(4,4,i)\n",
    "        plt.scatter(df1[feature], df2[feature], marker='+')\n",
    "        plt.xlabel(feature, fontsize=9)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will show just 5% of the data. On x axis we shwo train values and on the y axis we show the test values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['var_0', 'var_1','var_2','var_3', 'var_4', 'var_5', 'var_6', 'var_7', \n",
    "           'var_8', 'var_9', 'var_10','var_11','var_12', 'var_13', 'var_14', 'var_15', \n",
    "           ]\n",
    "plot_feature_scatter(train_df[::20],test_df[::20], features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution of target value in train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {}% target values with 1\".format(100 * train_df[\"target\"].value_counts()[1]/train_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is unbalanced with respect with target value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density plots of features\n",
    "\n",
    "Let's show now the density plot of variables in train dataset.\n",
    "\n",
    "We represent with different colors the distribution for values with target value 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution(df1, df2, label1, label2, features):\n",
    "    i = 0\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(10,10,figsize=(18,22))\n",
    "\n",
    "    for feature in features:\n",
    "        i += 1\n",
    "        plt.subplot(10,10,i)\n",
    "        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n",
    "        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n",
    "        plt.xlabel(feature, fontsize=9)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis='x', which='major', labelsize=6, pad=-6)\n",
    "        plt.tick_params(axis='y', which='major', labelsize=6)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 100 values are displayed in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = train_df.loc[train_df['target'] == 0]\n",
    "t1 = train_df.loc[train_df['target'] == 1]\n",
    "features = train_df.columns.values[2:102]\n",
    "plot_feature_distribution(t0, t1, '0', '1', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df.columns.values[102:202]\n",
    "plot_feature_distribution(t0, t1, '0', '1', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that there is a considerable number of features with significant differentt distribution for the tow target values.\n",
    "\n",
    "For example, var_0, var_1, var_2, var_5, var_9, var_13, var_106, var_109, var_139 and many others.\n",
    "\n",
    "Also some features, like var_2, var_13, var_26, var_55, var_175, var_184, var_196 shows a distribution that resambles to a bivariate distribution\n",
    "\n",
    "We will take this into consideration in the future for the selection of the features for our prediction model.\n",
    "\n",
    "Let's now look to the distribution of the same features in parallel in train and test datasets.\n",
    "\n",
    "The first 100 values are displayed in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df.columns.values[2:102]\n",
    "plot_feature_distribution(train_df, test_df, 'train', 'test', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df.columns.values[102:202]\n",
    "plot_feature_distribution(train_df, test_df, 'train', 'test', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test seems to be well balanced with respect with distribution of the numberic variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of mean and std\n",
    "\n",
    "Let's check the distribution of the mean values per now in the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "features = train_df.columns.values[2:202]\n",
    "plt.title(\"Distribution of mean values per row in the train and test set\")\n",
    "sns.distplot(train_df[features].mean(axis=1),color=\"green\", kde=True,bins=120, label='train')\n",
    "sns.distplot(test_df[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution of the mean values per columns in the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of mean values per column in the train and test set\")\n",
    "sns.distplot(train_df[features].mean(axis=0),color=\"magenta\",kde=True,bins=120, label='train')\n",
    "sns.distplot(test_df[features].mean(axis=0),color=\"darkblue\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the distribution of standard deviation of values per row for train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of std values per row in the train and test set\")\n",
    "sns.distplot(train_df[features].std(axis=1),color=\"black\", kde=True,bins=120, label='train')\n",
    "sns.distplot(test_df[features].std(axis=1),color=\"red\", kde=True,bins=120, label='test')\n",
    "plt.legend();plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution of the standard deviation of values per columns in the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of std values per column in the train and test set\")\n",
    "sns.distplot(train_df[features].std(axis=0),color=\"blue\",kde=True,bins=120, label='train')\n",
    "sns.distplot(test_df[features].std(axis=0),color=\"green\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now the distribution of the mean value per row in the train dataset, grouped by value of target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = train_df.loc[train_df['target'] == 0]\n",
    "t1 = train_df.loc[train_df['target'] == 1]\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of mean values per row in the train set\")\n",
    "sns.distplot(t0[features].mean(axis=1),color=\"red\", kde=True,bins=120, label='target = 0')\n",
    "sns.distplot(t1[features].mean(axis=1),color=\"blue\", kde=True,bins=120, label='target = 1')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now the distribution of the mean value per column in the train dataset, grouped by value of target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of mean values per column in the train set\")\n",
    "sns.distplot(t0[features].mean(axis=0),color=\"green\", kde=True,bins=120, label='target = 0')\n",
    "sns.distplot(t1[features].mean(axis=0),color=\"darkblue\", kde=True,bins=120, label='target = 1')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of min and max\n",
    "\n",
    "Let's check the distribution of min per row in the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "features = train_df.columns.values[2:202]\n",
    "plt.title(\"Distribution of min values per row in the train and test set\")\n",
    "sns.distplot(train_df[features].min(axis=1),color=\"red\", kde=True,bins=120, label='train')\n",
    "sns.distplot(test_df[features].min(axis=1),color=\"orange\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A long queue to the lower values for both, extended as long as to -80 for test set, is observed.\n",
    "\n",
    "Let's now show the distribution of min per column in the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "features = train_df.columns.values[2:202]\n",
    "plt.title(\"Distribution of min values per column in the train and test set\")\n",
    "sns.distplot(train_df[features].min(axis=0),color=\"magenta\", kde=True,bins=120, label='train')\n",
    "sns.distplot(test_df[features].min(axis=0),color=\"darkblue\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now the distribution of max values per rows for train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "features = train_df.columns.values[2:202]\n",
    "plt.title(\"Distribution of max values per row in the train and test set\")\n",
    "sns.distplot(train_df[features].max(axis=1),color=\"brown\", kde=True,bins=120, label='train')\n",
    "sns.distplot(test_df[features].max(axis=1),color=\"yellow\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show now the max distribution on columns for train and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "features = train_df.columns.values[2:202]\n",
    "plt.title(\"Distribution of max values per column in the train and test set\")\n",
    "sns.distplot(train_df[features].max(axis=0),color=\"blue\", kde=True,bins=120, label='train')\n",
    "sns.distplot(test_df[features].max(axis=0),color=\"red\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show now the distributions of min values per row in train set, separated on the values of target (0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = train_df.loc[train_df['target'] == 0]\n",
    "t1 = train_df.loc[train_df['target'] == 1]\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of min values per row in the train set\")\n",
    "sns.distplot(t0[features].min(axis=1),color=\"orange\", kde=True,bins=120, label='target = 0')\n",
    "sns.distplot(t1[features].min(axis=1),color=\"darkblue\", kde=True,bins=120, label='target = 1')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show here the distribution of min values per columns in train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of min values per column in the train set\")\n",
    "sns.distplot(t0[features].min(axis=0),color=\"red\", kde=True,bins=120, label='target = 0')\n",
    "sns.distplot(t1[features].min(axis=0),color=\"blue\", kde=True,bins=120, label='target = 1')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show now the distribution of max values per rown in the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of max values per row in the train set\")\n",
    "sns.distplot(t0[features].max(axis=1),color=\"gold\", kde=True,bins=120, label='target = 0')\n",
    "sns.distplot(t1[features].max(axis=1),color=\"darkblue\", kde=True,bins=120, label='target = 1')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show also the distribution of max values per columns in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of max values per column in the train set\")\n",
    "sns.distplot(t0[features].max(axis=0),color=\"red\", kde=True,bins=120, label='target = 0')\n",
    "sns.distplot(t1[features].max(axis=0),color=\"blue\", kde=True,bins=120, label='target = 1')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of skew and kurtosis\n",
    "\n",
    "Let's see now what is the distribution of skew values per rows and columns.\n",
    "\n",
    "Let's see first the distribution of skewness calculated per rows in train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Distribution of skew per row in the train and test set\")\n",
    "sns.distplot(train_df[features].skew(axis=1),color=\"red\", kde=True,bins=120, label='train')\n",
    "sns.distplot(test_df[features].skew(axis=1),color=\"orange\", kde=True,bins=120, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and so many tries..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features correlation\n",
    "\n",
    "We calculate now the correlation between the features in train set.\n",
    "\n",
    "The following table shows teh first 10 the least correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "correlations = train_df[features].corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\n",
    "correlations = correlations[correlations['level_0'] != correlations['level_1']]\n",
    "correlations.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look to the top most correlated features, besides the same feature pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see also the least correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between the features is very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate values\n",
    "\n",
    "Let's now check how many duplicate values exists per columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "features = train_df.columns.values[2:202]\n",
    "unique_max_train = []\n",
    "unique_max_test = []\n",
    "for feature in features:\n",
    "    values = train_df[feature].value_counts()\n",
    "    unique_max_train.append([feature, values.max(), values.idxmax()])\n",
    "    values = test_df[feature].value_counts()\n",
    "    unique_max_test.append([feature, values.max(), values.idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the top 15 max of duplicate values per train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose((pd.DataFrame(unique_max_train, columns=['Feature', 'Max duplicates', 'Value'])).\\\n",
    "            sort_values(by = 'Max duplicates', ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see also the top 15 number of duplicates values per test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose((pd.DataFrame(unique_max_test, columns=['Feature', 'Max duplicates', 'Value'])).\\\n",
    "            sort_values(by = 'Max duplicates', ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same columns in train and test set have the same or very close number of duplicates of same or very close values. This is an interesting pattern that we might be able to use in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "This section is under consturction.\n",
    "\n",
    "Let's calculate for starting few aggregated values for the existing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "idx = features = train_df.columns.values[2:202]\n",
    "for df in [test_df, train_df]:\n",
    "    df['sum'] = df[idx].sum(axis=1)  \n",
    "    df['min'] = df[idx].min(axis=1)\n",
    "    df['max'] = df[idx].max(axis=1)\n",
    "    df['mean'] = df[idx].mean(axis=1)\n",
    "    df['std'] = df[idx].std(axis=1)\n",
    "    df['skew'] = df[idx].skew(axis=1)\n",
    "    df['kurt'] = df[idx].kurtosis(axis=1)\n",
    "    df['med'] = df[idx].median(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the new created features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df.columns[202:]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df.columns[201:]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_new_feature_distribution(df1, df2, label1, label2, features):\n",
    "    i = 0\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2,4,figsize=(18,8))\n",
    "\n",
    "    for feature in features:\n",
    "        i += 1\n",
    "        plt.subplot(2,4,i)\n",
    "        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n",
    "        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n",
    "        plt.xlabel(feature, fontsize=11)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis='x', which='major', labelsize=8)\n",
    "        plt.tick_params(axis='y', which='major', labelsize=8)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution of these new, engineered features.\n",
    "\n",
    "We plot first the distribution of new features, grouped by value of corresponding target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = train_df.loc[train_df['target'] == 0]\n",
    "t1 = train_df.loc[train_df['target'] == 1]\n",
    "features = train_df.columns.values[202:]\n",
    "plot_new_feature_distribution(t0, t1, 'target: 0', 'target: 1', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the distribution of new features values for train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df.columns.values[202:]\n",
    "plot_new_feature_distribution(train_df, test_df, 'train', 'test', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add rounded features.\n",
    "\n",
    "Note: this is a work in progress, some of the features added here will be later dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "for feature in features:\n",
    "    train_df['r2_'+feature] = np.round(train_df[feature], 2)\n",
    "    test_df['r2_'+feature] = np.round(test_df[feature], 2)\n",
    "    train_df['r1_'+feature] = np.round(train_df[feature], 1)\n",
    "    test_df['r1_'+feature] = np.round(test_df[feature], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many features we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train and test columns: {} {}'.format(len(train_df.columns), len(test_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "From the train columns list, we drop the ID and target to form the features list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the hyperparameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=44000)\n",
    "folds = StratifiedKFold(n_splits=2, shuffle=False, random_state=44000)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "#     num_round = 1000000\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 3000)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:150].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FI.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "We submit the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
